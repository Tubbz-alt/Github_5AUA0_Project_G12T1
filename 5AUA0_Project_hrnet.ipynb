{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5AUA0_Project_hrnet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "efmYI6dheXaV",
        "iaoJNaKqpt2Y",
        "lXXWsAgFfhxw",
        "tGefdpZWpT7g",
        "tvnRWa3gpZBA",
        "o2AzIRo9CoYH",
        "78iK-AzqCuTH"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJ8DecDfgjS1",
        "colab_type": "text"
      },
      "source": [
        "# Mount Google Drive\n",
        "Add a shortcut from the shared folder \"5AUA0_Project_Group12_Team1\" to your own drive.\n",
        "\n",
        "Run the next cell to start working on the project!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt5M6wrAqZCD",
        "colab_type": "code",
        "outputId": "3e3e4b1b-99c3-45cc-f96c-8c1be0bd6c48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "# Add a shortcut from the shared folder to your own drive\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efmYI6dheXaV",
        "colab_type": "text"
      },
      "source": [
        "# Clone GitHub repo\n",
        "Run the next two cells to clone the GitHub repo. This has now already been done, so should not be necessary to do it again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3H0NqyzuciM",
        "colab_type": "code",
        "outputId": "9acfdcf8-e207-4b4b-89c0-06ffcfa9c6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7bvEp_cGQJ",
        "colab_type": "code",
        "outputId": "0332ecc6-fa42-4840-ef4d-014b98570644",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Go to the base folder in Google Drive\n",
        "%cd /content/gdrive/My\\ Drive/5AUA0_Project_Group12_Team1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/5AUA0_Project_Group12_Team1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iBBREoa6Bat1",
        "outputId": "8929ffc8-9f75-4c82-9020-f90ebedd19cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "# Clone the GitHub repo \"Github_5AUA0_Project_G12T1\"\n",
        "# Only have to do this ones!\n",
        "!git clone https://github.com/nadinenijssen/Github_5AUA0_Project_G12T1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Github_5AUA0_Project_G12T1'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (145/145), done.\u001b[K\n",
            "remote: Total 184 (delta 32), reused 165 (delta 27), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (184/184), 43.55 MiB | 12.69 MiB/s, done.\n",
            "Resolving deltas: 100% (32/32), done.\n",
            "Checking out files: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_kXso6Xd7CH",
        "colab_type": "text"
      },
      "source": [
        "# Pull changes from GitHub repo\n",
        "Run the next to cells before working on the project to sync the Google Drive folder with the GitHub repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7LY9KW1bnQH",
        "colab_type": "code",
        "outputId": "e2cc418b-1b95-4b89-f426-2de76af82ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Go to the cloned repo folder\n",
        "%cd /content/gdrive/My\\ Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "63705713-6b83-473d-afa8-5a4dd534b4db",
        "id": "aV8S9ha_BZVS",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "# git pull all changes that we made to the repo\n",
        "!git pull"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  20% (1/5)\u001b[K\rremote: Compressing objects:  40% (2/5)\u001b[K\rremote: Compressing objects:  60% (3/5)\u001b[K\rremote: Compressing objects:  80% (4/5)\u001b[K\rremote: Compressing objects: 100% (5/5)\u001b[K\rremote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 5 (delta 3), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  20% (1/5)   \rUnpacking objects:  40% (2/5)   \rUnpacking objects:  60% (3/5)   \rUnpacking objects:  80% (4/5)   \rUnpacking objects: 100% (5/5)   \rUnpacking objects: 100% (5/5), done.\n",
            "From https://github.com/nadinenijssen/Github_5AUA0_Project_G12T1\n",
            "   720093a..ab07a5b  master     -> origin/master\n",
            "Updating 720093a..ab07a5b\n",
            "Fast-forward\n",
            " FairMOT/src/track.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaoJNaKqpt2Y",
        "colab_type": "text"
      },
      "source": [
        "# Demo from FairMOT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXXWsAgFfhxw",
        "colab_type": "text"
      },
      "source": [
        "## Demo with HRNetV2_w18 baseline model\n",
        "### *Works with \"Demo_test\" folder on Google Drive*\n",
        "The next cells show the steps to run the demo.py from FairMOT with the HRNetV2_w18 baseline model.\n",
        "\n",
        "Make sure to first comment lines with 'dcn' in src/libs/models/model.py (6 lines at the top)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU1WfeHGleWF",
        "colab_type": "code",
        "outputId": "e5645061-de17-42e0-dce2-26f50ef078e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# FairMOT demo.py with HRNetV2_w18 baseline model:\n",
        "\n",
        "# Install other requirements\n",
        "# first change to the right folder\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Demo_test/FairMOT')\n",
        "%pwd # print current location"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/.shortcut-targets-by-id/10m49XUykzV-lqWDft1-stDmLxt5dixAS/5AUA0_Project_Group12_Team1/Github_Nadine_test/FairMOT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujca0hCzqc8g",
        "colab_type": "code",
        "outputId": "2eb86287-7e78-45f8-ef17-cfc03521b80b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# FairMOT demo.py with HRNetV2_w18 baseline model:\n",
        "\n",
        "# then install requirements\n",
        "!pip install -r requirements.txt\n",
        "# restart runtime when required"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting cython-bbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/b9/fc7d60e8c3b29cc0ff24a3bb3c4b7457e10b7610fbb2893741b623487b34/cython_bbox-0.1.3.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.48.0)\n",
            "Collecting progress\n",
            "  Downloading https://files.pythonhosted.org/packages/38/ef/2e887b3d2b248916fc2121889ce68af8a16aaddbe82f9ae6533c24ff0d2b/progress-1.5.tar.gz\n",
            "Collecting motmetrics\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/28/9c3bc8e2a87f4c9e7b04ab72856ec7f9895a66681a65973ffaf9562ef879/motmetrics-1.2.0-py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.2.1)\n",
            "Collecting lap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 19.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (2.5.9)\n",
            "Collecting Pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 39.7MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python->-r requirements.txt (line 2)) (1.18.4)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 5)) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 5)) (46.1.3)\n",
            "Collecting flake8-import-order\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/52/cf2d6e2c505644ca06de2f6f3546f1e4f2b7be34246c9e0757c6048868f9/flake8_import_order-0.18.1-py2.py3-none-any.whl\n",
            "Collecting xmltodict>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from motmetrics->-r requirements.txt (line 7)) (3.6.4)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from motmetrics->-r requirements.txt (line 7)) (1.0.3)\n",
            "Collecting flake8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/47/36e51603431e1a5289eb41636199d2c225fcb1ca286e29c02d219c8e6e88/flake8-3.8.1-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 11.6MB/s \n",
            "\u001b[?25hCollecting pytest-benchmark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/1e/180579ad3bc53fe3181ef3843f0602f4db77f3609e5e5069a0ec194ff213/pytest_benchmark-3.2.3-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 13)) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 13)) (3.10.0)\n",
            "Collecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (1.8.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (8.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (19.3.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.1->motmetrics->-r requirements.txt (line 7)) (2018.9)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting pyflakes<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/5b/fd01b0c696f2f9a6d2c839883b642493b431f28fa32b29abc465ef675473/pyflakes-2.2.0-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from flake8->motmetrics->-r requirements.txt (line 7)) (1.6.0)\n",
            "Collecting py-cpuinfo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/60/63f28a5401da733043abe7053e7d9591491b4784c4f87c339bf51215aa0a/py-cpuinfo-5.0.0.tar.gz (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 13.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->flake8->motmetrics->-r requirements.txt (line 7)) (3.1.0)\n",
            "Building wheels for collected packages: cython-bbox, progress, lap, py-cpuinfo\n",
            "  Building wheel for cython-bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp36-cp36m-linux_x86_64.whl size=57428 sha256=55eb7167ab8c50f0b20fc6a896ad9633d71fdf8cf9009f8cc8433e6b179052c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/31/b5/9246d5988e79ef89dc28b894835d2f305e23c1e5f4f80278ee\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-cp36-none-any.whl size=8074 sha256=d35da02875cd139ef12e06ae6d2f2938875cfbc6673f31c50db0b4ce1f85eab1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c8/80/32a294e3041f006c661838c05a411c7b7ffc60ff939d14e116\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp36-cp36m-linux_x86_64.whl size=1589016 sha256=29ad5f0378d6aba7a724920c402da7b09966fb4b54b492cb8bf0de2e2900b0cb\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/3e/af/eddcd6ffaa27df8d0ddac573758f8953c4e57c64c4c8c8b7d0\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-cp36-none-any.whl size=18684 sha256=6853539bce15373d36992169f34cbd2f8c893fd374b0668b2914c67b4da00d79\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/7e/a9/b982d0fea22b7e4ae5619de949570cde5ad55420cec16e86a5\n",
            "Successfully built cython-bbox progress lap py-cpuinfo\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest-benchmark 3.2.3 has requirement pytest>=3.8, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: yacs, cython-bbox, progress, pycodestyle, flake8-import-order, xmltodict, mccabe, pyflakes, flake8, py-cpuinfo, pytest-benchmark, motmetrics, lap, Pillow, tensorboardX\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-6.2.2 cython-bbox-0.1.3 flake8-3.8.1 flake8-import-order-0.18.1 lap-0.4.0 mccabe-0.6.1 motmetrics-1.2.0 progress-1.5 py-cpuinfo-5.0.0 pycodestyle-2.6.0 pyflakes-2.2.0 pytest-benchmark-3.2.3 tensorboardX-2.0 xmltodict-0.12.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoQCPdXC59I8",
        "colab_type": "code",
        "outputId": "b363c140-1db9-45a2-fe12-afcdc97074b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# FairMOT demo.py with HRNetV2_w18 baseline model:\n",
        "\n",
        "# Time to run the demo!\n",
        "# If using the DLA-34 baseline model:\n",
        "# first change to the right folder\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Demo_test/FairMOT/src')\n",
        "!pwd"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/.shortcut-targets-by-id/10m49XUykzV-lqWDft1-stDmLxt5dixAS/5AUA0_Project_Group12_Team1/Github_Nadine_test/FairMOT/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GklJkfLTvDr4",
        "colab_type": "code",
        "outputId": "90a01019-f426-4835-8c8c-c609dc4b70ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# FairMOT demo.py with HRNetV2_w18 baseline model:\n",
        "\n",
        "# then run the demo\n",
        "# !!!!! comment lines with 'dcn' in src/libs/models/model.py (6 lines at the top)\n",
        "!python demo.py mot --load_model ../models/all_hrnet_v2_w18.pth --arch hrnet_18 --reid_dim 128 --conf_thres 0.4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fix size testing.\n",
            "training chunk_sizes: [6, 6]\n",
            "The output will be saved to  /content/gdrive/.shortcut-targets-by-id/10m49XUykzV-lqWDft1-stDmLxt5dixAS/5AUA0_Project_Group12_Team1/Github_Nadine_test/FairMOT/src/lib/../../exp/mot/default\n",
            "heads {'hm': 1, 'wh': 2, 'id': 128, 'reg': 2}\n",
            "2020-05-12 12:33:28 [INFO]: Starting tracking...\n",
            "Lenth of the video: 1500 frames\n",
            "Creating model...\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "2020-05-12 12:33:53 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "2020-05-12 12:34:13 [INFO]: Processing frame 20 (12.54 fps)\n",
            "2020-05-12 12:34:25 [INFO]: Processing frame 40 (13.79 fps)\n",
            "2020-05-12 12:34:34 [INFO]: Processing frame 60 (14.32 fps)\n",
            "2020-05-12 12:34:49 [INFO]: Processing frame 80 (14.53 fps)\n",
            "2020-05-12 12:34:59 [INFO]: Processing frame 100 (14.71 fps)\n",
            "2020-05-12 12:35:09 [INFO]: Processing frame 120 (14.82 fps)\n",
            "2020-05-12 12:35:17 [INFO]: Processing frame 140 (14.94 fps)\n",
            "2020-05-12 12:35:26 [INFO]: Processing frame 160 (15.00 fps)\n",
            "2020-05-12 12:35:36 [INFO]: Processing frame 180 (15.04 fps)\n",
            "2020-05-12 12:35:47 [INFO]: Processing frame 200 (15.07 fps)\n",
            "2020-05-12 12:35:57 [INFO]: Processing frame 220 (15.10 fps)\n",
            "2020-05-12 12:36:07 [INFO]: Processing frame 240 (15.13 fps)\n",
            "2020-05-12 12:36:17 [INFO]: Processing frame 260 (15.14 fps)\n",
            "2020-05-12 12:36:27 [INFO]: Processing frame 280 (15.17 fps)\n",
            "2020-05-12 12:36:37 [INFO]: Processing frame 300 (15.19 fps)\n",
            "2020-05-12 12:36:46 [INFO]: Processing frame 320 (15.20 fps)\n",
            "2020-05-12 12:36:56 [INFO]: Processing frame 340 (15.19 fps)\n",
            "2020-05-12 12:37:06 [INFO]: Processing frame 360 (15.19 fps)\n",
            "2020-05-12 12:37:16 [INFO]: Processing frame 380 (15.17 fps)\n",
            "2020-05-12 12:37:27 [INFO]: Processing frame 400 (15.16 fps)\n",
            "2020-05-12 12:37:37 [INFO]: Processing frame 420 (15.16 fps)\n",
            "2020-05-12 12:37:48 [INFO]: Processing frame 440 (15.14 fps)\n",
            "2020-05-12 12:37:56 [INFO]: Processing frame 460 (15.14 fps)\n",
            "2020-05-12 12:38:04 [INFO]: Processing frame 480 (15.15 fps)\n",
            "2020-05-12 12:38:10 [INFO]: Processing frame 500 (15.17 fps)\n",
            "2020-05-12 12:38:17 [INFO]: Processing frame 520 (15.20 fps)\n",
            "2020-05-12 12:38:24 [INFO]: Processing frame 540 (15.20 fps)\n",
            "2020-05-12 12:38:32 [INFO]: Processing frame 560 (15.22 fps)\n",
            "2020-05-12 12:38:38 [INFO]: Processing frame 580 (15.22 fps)\n",
            "2020-05-12 12:38:44 [INFO]: Processing frame 600 (15.23 fps)\n",
            "2020-05-12 12:38:50 [INFO]: Processing frame 620 (15.24 fps)\n",
            "2020-05-12 12:38:57 [INFO]: Processing frame 640 (15.25 fps)\n",
            "2020-05-12 12:39:04 [INFO]: Processing frame 660 (15.25 fps)\n",
            "2020-05-12 12:39:13 [INFO]: Processing frame 680 (15.26 fps)\n",
            "2020-05-12 12:39:21 [INFO]: Processing frame 700 (15.26 fps)\n",
            "2020-05-12 12:39:29 [INFO]: Processing frame 720 (15.27 fps)\n",
            "2020-05-12 12:39:37 [INFO]: Processing frame 740 (15.27 fps)\n",
            "2020-05-12 12:39:44 [INFO]: Processing frame 760 (15.26 fps)\n",
            "2020-05-12 12:39:50 [INFO]: Processing frame 780 (15.26 fps)\n",
            "2020-05-12 12:39:55 [INFO]: Processing frame 800 (15.26 fps)\n",
            "2020-05-12 12:40:02 [INFO]: Processing frame 820 (15.27 fps)\n",
            "2020-05-12 12:40:08 [INFO]: Processing frame 840 (15.27 fps)\n",
            "2020-05-12 12:40:15 [INFO]: Processing frame 860 (15.26 fps)\n",
            "2020-05-12 12:40:22 [INFO]: Processing frame 880 (15.25 fps)\n",
            "2020-05-12 12:40:30 [INFO]: Processing frame 900 (15.24 fps)\n",
            "2020-05-12 12:40:39 [INFO]: Processing frame 920 (15.24 fps)\n",
            "2020-05-12 12:40:46 [INFO]: Processing frame 940 (15.24 fps)\n",
            "2020-05-12 12:40:54 [INFO]: Processing frame 960 (15.25 fps)\n",
            "2020-05-12 12:41:01 [INFO]: Processing frame 980 (15.26 fps)\n",
            "2020-05-12 12:41:08 [INFO]: Processing frame 1000 (15.26 fps)\n",
            "2020-05-12 12:41:17 [INFO]: Processing frame 1020 (15.26 fps)\n",
            "2020-05-12 12:41:24 [INFO]: Processing frame 1040 (15.26 fps)\n",
            "2020-05-12 12:41:32 [INFO]: Processing frame 1060 (15.27 fps)\n",
            "2020-05-12 12:41:38 [INFO]: Processing frame 1080 (15.27 fps)\n",
            "2020-05-12 12:41:43 [INFO]: Processing frame 1100 (15.28 fps)\n",
            "2020-05-12 12:41:49 [INFO]: Processing frame 1120 (15.29 fps)\n",
            "2020-05-12 12:41:56 [INFO]: Processing frame 1140 (15.31 fps)\n",
            "2020-05-12 12:42:03 [INFO]: Processing frame 1160 (15.32 fps)\n",
            "2020-05-12 12:42:09 [INFO]: Processing frame 1180 (15.33 fps)\n",
            "2020-05-12 12:42:14 [INFO]: Processing frame 1200 (15.34 fps)\n",
            "2020-05-12 12:42:24 [INFO]: Processing frame 1220 (15.34 fps)\n",
            "2020-05-12 12:42:35 [INFO]: Processing frame 1240 (15.36 fps)\n",
            "2020-05-12 12:42:45 [INFO]: Processing frame 1260 (15.37 fps)\n",
            "2020-05-12 12:42:56 [INFO]: Processing frame 1280 (15.37 fps)\n",
            "2020-05-12 12:43:05 [INFO]: Processing frame 1300 (15.37 fps)\n",
            "2020-05-12 12:43:15 [INFO]: Processing frame 1320 (15.37 fps)\n",
            "2020-05-12 12:43:24 [INFO]: Processing frame 1340 (15.38 fps)\n",
            "2020-05-12 12:43:34 [INFO]: Processing frame 1360 (15.38 fps)\n",
            "2020-05-12 12:43:44 [INFO]: Processing frame 1380 (15.38 fps)\n",
            "2020-05-12 12:43:53 [INFO]: Processing frame 1400 (15.38 fps)\n",
            "2020-05-12 12:44:05 [INFO]: Processing frame 1420 (15.38 fps)\n",
            "2020-05-12 12:44:14 [INFO]: Processing frame 1440 (15.38 fps)\n",
            "2020-05-12 12:44:23 [INFO]: Processing frame 1460 (15.39 fps)\n",
            "2020-05-12 12:44:33 [INFO]: Processing frame 1480 (15.39 fps)\n",
            "2020-05-12 12:44:44 [INFO]: save results to ../results/results.txt\n",
            "ffmpeg version 3.4.6-0ubuntu0.18.04.1 Copyright (c) 2000-2019 the FFmpeg developers\n",
            "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
            "  libavutil      55. 78.100 / 55. 78.100\n",
            "  libavcodec     57.107.100 / 57.107.100\n",
            "  libavformat    57. 83.100 / 57. 83.100\n",
            "  libavdevice    57. 10.100 / 57. 10.100\n",
            "  libavfilter     6.107.100 /  6.107.100\n",
            "  libavresample   3.  7.  0 /  3.  7.  0\n",
            "  libswscale      4.  8.100 /  4.  8.100\n",
            "  libswresample   2.  9.100 /  2.  9.100\n",
            "  libpostproc    54.  7.100 / 54.  7.100\n",
            "Input #0, image2, from '../results/frame/%05d.jpg':\n",
            "  Duration: 00:01:00.00, start: 0.000000, bitrate: N/A\n",
            "    Stream #0:0: Video: mjpeg, yuvj420p(pc, bt470bg/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 25 fps, 25 tbr, 25 tbn, 25 tbc\n",
            "\u001b[0;33mPlease use -b:a or -b:v, -b is ambiguous\n",
            "\u001b[0mFile '../results/result.mp4' already exists. Overwrite ? [y/N] y\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mjpeg (native) -> mpeg4 (native))\n",
            "Press [q] to stop, [?] for help\n",
            "\u001b[1;34m[swscaler @ 0x55a26a4b8000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
            "\u001b[0mOutput #0, mp4, to '../results/result.mp4':\n",
            "  Metadata:\n",
            "    encoder         : Lavf57.83.100\n",
            "    Stream #0:0: Video: mpeg4 (mp4v / 0x7634706D), yuv420p, 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 5000 kb/s, 25 fps, 12800 tbn, 25 tbc\n",
            "    Metadata:\n",
            "      encoder         : Lavc57.107.100 mpeg4\n",
            "    Side data:\n",
            "      cpb: bitrate max/min/avg: 0/0/5000000 buffer size: 0 vbv_delay: -1\n",
            "frame=  916 fps= 42 q=13.7 Lsize=   22564kB time=00:00:36.60 bitrate=5050.5kbits/s speed=1.67x    \n",
            "video:22559kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.022502%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVvuJpzag-rd",
        "colab_type": "text"
      },
      "source": [
        "# Training the network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGefdpZWpT7g",
        "colab_type": "text"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSfF0tuKg-KP",
        "colab_type": "code",
        "outputId": "3c8d8c96-32cc-4f83-9ad6-a8670eb589cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Install requirements\n",
        "# first change to the right folder\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT')\n",
        "%pwd # print current location"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye_L_6hzo4hJ",
        "colab_type": "code",
        "outputId": "893f7dee-b9ba-4487-b361-6af41160f70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# then install requirements\n",
        "!pip install -r requirements.txt\n",
        "# restart runtime when required"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting yacs\n",
            "  Downloading https://files.pythonhosted.org/packages/81/3b/40e876afde9f5ffa1cfdce10565aba85b0dc2e067ed551dfb566cfee6d4d/yacs-0.1.7-py3-none-any.whl\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (4.1.2.30)\n",
            "Collecting cython-bbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/b9/fc7d60e8c3b29cc0ff24a3bb3c4b7457e10b7610fbb2893741b623487b34/cython_bbox-0.1.3.tar.gz (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (0.48.0)\n",
            "Collecting progress\n",
            "  Downloading https://files.pythonhosted.org/packages/38/ef/2e887b3d2b248916fc2121889ce68af8a16aaddbe82f9ae6533c24ff0d2b/progress-1.5.tar.gz\n",
            "Collecting motmetrics\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/28/9c3bc8e2a87f4c9e7b04ab72856ec7f9895a66681a65973ffaf9562ef879/motmetrics-1.2.0-py3-none-any.whl (151kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 6.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (3.2.1)\n",
            "Collecting lap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 11)) (2.5.9)\n",
            "Collecting Pillow==6.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/fd/bbbc569f98f47813c50a116b539d97b3b17a86ac7a309f83b2022d26caf2/Pillow-6.2.2-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 17.6MB/s \n",
            "\u001b[?25hCollecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 29.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from yacs->-r requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python->-r requirements.txt (line 2)) (1.18.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 5)) (46.3.0)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba->-r requirements.txt (line 5)) (0.31.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from motmetrics->-r requirements.txt (line 7)) (3.6.4)\n",
            "Collecting pytest-benchmark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/1e/180579ad3bc53fe3181ef3843f0602f4db77f3609e5e5069a0ec194ff213/pytest_benchmark-3.2.3-py2.py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.9MB/s \n",
            "\u001b[?25hCollecting flake8-import-order\n",
            "  Downloading https://files.pythonhosted.org/packages/ab/52/cf2d6e2c505644ca06de2f6f3546f1e4f2b7be34246c9e0757c6048868f9/flake8_import_order-0.18.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.6/dist-packages (from motmetrics->-r requirements.txt (line 7)) (1.0.3)\n",
            "Collecting flake8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/47/36e51603431e1a5289eb41636199d2c225fcb1ca286e29c02d219c8e6e88/flake8-3.8.1-py2.py3-none-any.whl (72kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.8MB/s \n",
            "\u001b[?25hCollecting xmltodict>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r requirements.txt (line 9)) (2.4.7)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 11)) (1.0.1)\n",
            "Requirement already satisfied: jdcal in /usr/local/lib/python3.6/dist-packages (from openpyxl->-r requirements.txt (line 11)) (1.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 13)) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r requirements.txt (line 13)) (3.10.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (8.2.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (1.8.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->motmetrics->-r requirements.txt (line 7)) (19.3.0)\n",
            "Collecting py-cpuinfo\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/60/63f28a5401da733043abe7053e7d9591491b4784c4f87c339bf51215aa0a/py-cpuinfo-5.0.0.tar.gz (82kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.8MB/s \n",
            "\u001b[?25hCollecting pycodestyle\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/5b/88879fb861ab79aef45c7e199cae3ef7af487b5603dcb363517a50602dd7/pycodestyle-2.6.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.1->motmetrics->-r requirements.txt (line 7)) (2018.9)\n",
            "Collecting mccabe<0.7.0,>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/87/89/479dc97e18549e21354893e4ee4ef36db1d237534982482c3681ee6e7b57/mccabe-0.6.1-py2.py3-none-any.whl\n",
            "Collecting pyflakes<2.3.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/5b/fd01b0c696f2f9a6d2c839883b642493b431f28fa32b29abc465ef675473/pyflakes-2.2.0-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from flake8->motmetrics->-r requirements.txt (line 7)) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->flake8->motmetrics->-r requirements.txt (line 7)) (3.1.0)\n",
            "Building wheels for collected packages: cython-bbox, progress, lap, py-cpuinfo\n",
            "  Building wheel for cython-bbox (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cython-bbox: filename=cython_bbox-0.1.3-cp36-cp36m-linux_x86_64.whl size=57427 sha256=9a84be56aae7023d137f3847b85998068df7070bba9172f2672f97bfe4b56657\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/31/b5/9246d5988e79ef89dc28b894835d2f305e23c1e5f4f80278ee\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progress: filename=progress-1.5-cp36-none-any.whl size=8074 sha256=54ca52673e1960f3ced4b7f3095921d5b3c34fb9c8d467f67f38281bb38e5689\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/c8/80/32a294e3041f006c661838c05a411c7b7ffc60ff939d14e116\n",
            "  Building wheel for lap (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lap: filename=lap-0.4.0-cp36-cp36m-linux_x86_64.whl size=1589041 sha256=f6ea8a1e9eda41c15effbcdb42cf6a43b5172177957fedda4b20d06048f4d85e\n",
            "  Stored in directory: /root/.cache/pip/wheels/da/3e/af/eddcd6ffaa27df8d0ddac573758f8953c4e57c64c4c8c8b7d0\n",
            "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-cpuinfo: filename=py_cpuinfo-5.0.0-cp36-none-any.whl size=18684 sha256=2736d3a649aa5ef9c7a6dd1efa373151113ac60880bbc1e5eba27eeafb203605\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/7e/a9/b982d0fea22b7e4ae5619de949570cde5ad55420cec16e86a5\n",
            "Successfully built cython-bbox progress lap py-cpuinfo\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytest-benchmark 3.2.3 has requirement pytest>=3.8, but you'll have pytest 3.6.4 which is incompatible.\u001b[0m\n",
            "Installing collected packages: yacs, cython-bbox, progress, py-cpuinfo, pytest-benchmark, pycodestyle, flake8-import-order, mccabe, pyflakes, flake8, xmltodict, motmetrics, lap, Pillow, tensorboardX\n",
            "  Found existing installation: Pillow 7.0.0\n",
            "    Uninstalling Pillow-7.0.0:\n",
            "      Successfully uninstalled Pillow-7.0.0\n",
            "Successfully installed Pillow-6.2.2 cython-bbox-0.1.3 flake8-3.8.1 flake8-import-order-0.18.1 lap-0.4.0 mccabe-0.6.1 motmetrics-1.2.0 progress-1.5 py-cpuinfo-5.0.0 pycodestyle-2.6.0 pyflakes-2.2.0 pytest-benchmark-3.2.3 tensorboardX-2.0 xmltodict-0.12.0 yacs-0.1.7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvnRWa3gpZBA",
        "colab_type": "text"
      },
      "source": [
        "## Start train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_CHMcZlw-_P",
        "colab_type": "code",
        "outputId": "429552fc-c7b6-4158-e0e3-3a5485d3804b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# import os\n",
        "# os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src')\n",
        "# %pwd # print current location\n",
        "\n",
        "# !python train.py mot --exp_id all_hrnet --gpus 0,1 --batch_size 8 --reid_dim 128 --arch 'hrnet_18'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FesxCh2NYh97",
        "colab_type": "code",
        "outputId": "f61fc70e-9722-4477-86d4-88cdaa2b9199",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src')\n",
        "%pwd # print current location"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2AzIRo9CoYH",
        "colab_type": "text"
      },
      "source": [
        "### Train from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446Sb_EyDlNW",
        "colab_type": "code",
        "outputId": "ee2f7cf6-3a1b-49e6-f504-2c764157e7ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# train from scratch\n",
        "!python train.py mot --exp_id all_hrnet --gpus '0' --batch_size 8 --reid_dim 128 --arch 'hrnet_18' --num_epochs 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using tensorboardX\n",
            "Fix size testing.\n",
            "training chunk_sizes: [8]\n",
            "The output will be saved to  /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet\n",
            "gpus 0\n",
            "Setting up data...\n",
            "================================================================================\n",
            "dataset summary\n",
            "OrderedDict([('mot17', 547.0)])\n",
            "total # identities: 548\n",
            "start index\n",
            "OrderedDict([('mot17', 0)])\n",
            "================================================================================\n",
            "heads {'hm': 1, 'wh': 2, 'id': 128, 'reg': 2}\n",
            "Namespace(K=128, arch='hrnet_18', batch_size=8, cat_spec_wh=False, chunk_sizes=[8], conf_thres=0.6, data_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data', dataset='jde', debug_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet/debug', dense_wh=False, det_thres=0.3, down_ratio=4, exp_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot', exp_id='all_hrnet', fix_res=True, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 1, 'wh': 2, 'id': 128, 'reg': 2}, hide_data_time=False, hm_weight=1, id_loss='ce', id_weight=1, img_size=(1088, 608), input_h=1088, input_res=1088, input_video='../videos/MOT16-03.mp4', input_w=608, keep_res=False, load_model='', lr=0.0001, lr_step=[20, 27], master_batch_size=8, mean=None, metric='loss', min_box_area=200, mse_loss=False, nID=548, nms_thres=0.4, norm_wh=False, not_cuda_benchmark=False, not_prefetch_test=False, not_reg_offset=False, num_classes=1, num_epochs=10, num_iters=-1, num_stacks=1, num_workers=8, off_weight=1, output_format='video', output_h=272, output_res=272, output_root='../results', output_w=152, pad=31, print_iter=0, reg_loss='l1', reg_offset=True, reid_dim=128, resume=False, root_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../..', save_all=False, save_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet', seed=317, std=None, task='mot', test=False, test_mot15=False, test_mot16=False, test_mot17=False, test_mot20=False, track_buffer=30, trainval=False, val_intervals=5, val_mot15=False, val_mot16=False, val_mot17=False, val_mot20=False, vis_thresh=0.5, wh_weight=0.1)\n",
            "cp: target 'Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet/logs_2020-05-20-12-28/' is not a directory\n",
            "Creating model...\n",
            "Starting training...\n",
            "\u001b[?25lmot/all_hrnet/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "\u001b[Kmot/all_hrnet |################################| train: [1][663/664]|Tot: 0:12:55 |ETA: 0:00:02 |loss 10.9754 |hm_loss 0.9299 |wh_loss 3.9791 |off_loss 0.2429 |id_loss 5.2006 |Data 0.001s(0.011s) |Net 1.168s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [2][663/664]|Tot: 0:12:53 |ETA: 0:00:02 |loss 7.6935 |hm_loss 0.6131 |wh_loss 2.0210 |off_loss 0.2253 |id_loss 4.0837 |Data 0.001s(0.010s) |Net 1.165s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [3][663/664]|Tot: 0:12:53 |ETA: 0:00:02 |loss 6.5166 |hm_loss 0.5155 |wh_loss 1.7362 |off_loss 0.2167 |id_loss 3.5596 |Data 0.001s(0.009s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [4][663/664]|Tot: 0:12:54 |ETA: 0:00:02 |loss 5.8235 |hm_loss 0.4598 |wh_loss 1.6194 |off_loss 0.2117 |id_loss 3.2357 |Data 0.001s(0.011s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [5][663/664]|Tot: 0:12:53 |ETA: 0:00:02 |loss 5.3542 |hm_loss 0.4226 |wh_loss 1.5232 |off_loss 0.2076 |id_loss 3.0206 |Data 0.001s(0.009s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [6][663/664]|Tot: 0:12:54 |ETA: 0:00:02 |loss 4.9939 |hm_loss 0.3956 |wh_loss 1.4512 |off_loss 0.2039 |id_loss 2.8527 |Data 0.001s(0.009s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [7][663/664]|Tot: 0:12:54 |ETA: 0:00:02 |loss 4.7496 |hm_loss 0.3753 |wh_loss 1.4341 |off_loss 0.2013 |id_loss 2.7366 |Data 0.001s(0.008s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [8][663/664]|Tot: 0:12:54 |ETA: 0:00:02 |loss 4.4974 |hm_loss 0.3521 |wh_loss 1.3796 |off_loss 0.1980 |id_loss 2.6311 |Data 0.001s(0.010s) |Net 1.166s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [9][663/664]|Tot: 0:12:52 |ETA: 0:00:02 |loss 4.3261 |hm_loss 0.3394 |wh_loss 1.3444 |off_loss 0.1957 |id_loss 2.5524 |Data 0.002s(0.010s) |Net 1.163s\n",
            "\u001b[Kmot/all_hrnet |################################| train: [10][663/664]|Tot: 0:12:53 |ETA: 0:00:02 |loss 4.1935 |hm_loss 0.3278 |wh_loss 1.3342 |off_loss 0.1951 |id_loss 2.4891 |Data 0.001s(0.010s) |Net 1.164s\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78iK-AzqCuTH",
        "colab_type": "text"
      },
      "source": [
        "### Resume training from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uWG-z3gpVJL",
        "colab_type": "code",
        "outputId": "1cfa318d-6d03-46ef-cafd-1f2f440aae38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# resume training the \"trained-from-scratch\" model\n",
        "!python train.py mot --exp_id all_hrnet --gpus '0' --batch_size 8 --reid_dim 128 --resume --arch 'hrnet_18' --num_epochs 30 --load_model ../exp/mot/all_hrnet/BS8_scratch/model_20.pth"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using tensorboardX\n",
            "Fix size testing.\n",
            "training chunk_sizes: [8]\n",
            "The output will be saved to  /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet\n",
            "gpus 0\n",
            "Setting up data...\n",
            "================================================================================\n",
            "dataset summary\n",
            "OrderedDict([('mot17', 547.0)])\n",
            "total # identities: 548\n",
            "start index\n",
            "OrderedDict([('mot17', 0)])\n",
            "================================================================================\n",
            "heads {'hm': 1, 'wh': 2, 'id': 128, 'reg': 2}\n",
            "Namespace(K=128, arch='hrnet_18', batch_size=8, cat_spec_wh=False, chunk_sizes=[8], conf_thres=0.6, data_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data', dataset='jde', debug_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet/debug', dense_wh=False, det_thres=0.3, down_ratio=4, exp_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot', exp_id='all_hrnet', fix_res=True, gpus=[0], gpus_str='0', head_conv=256, heads={'hm': 1, 'wh': 2, 'id': 128, 'reg': 2}, hide_data_time=False, hm_weight=1, id_loss='ce', id_weight=1, img_size=(1088, 608), input_h=1088, input_res=1088, input_video='../videos/MOT16-03.mp4', input_w=608, keep_res=False, load_model='../exp/mot/all_hrnet/BS8_scratch/model_20.pth', lr=0.0001, lr_step=[20, 27], master_batch_size=8, mean=None, metric='loss', min_box_area=200, mse_loss=False, nID=548, nms_thres=0.4, norm_wh=False, not_cuda_benchmark=False, not_prefetch_test=False, not_reg_offset=False, num_classes=1, num_epochs=30, num_iters=-1, num_stacks=1, num_workers=8, off_weight=1, output_format='video', output_h=272, output_res=272, output_root='../results', output_w=152, pad=31, print_iter=0, reg_loss='l1', reg_offset=True, reid_dim=128, resume=True, root_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../..', save_all=False, save_dir='/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet', seed=317, std=None, task='mot', test=False, test_mot15=False, test_mot16=False, test_mot17=False, test_mot20=False, track_buffer=30, trainval=False, val_intervals=5, val_mot15=False, val_mot16=False, val_mot17=False, val_mot20=False, vis_thresh=0.5, wh_weight=0.1)\n",
            "cp: target 'Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/all_hrnet/logs_2020-05-21-10-44/' is not a directory\n",
            "Creating model...\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Resumed optimizer with start lr 1e-05\n",
            "Starting training...\n",
            "\u001b[?25lmot/all_hrnetTraceback (most recent call last):\n",
            "  File \"train.py\", line 105, in <module>\n",
            "    main(opt)\n",
            "  File \"train.py\", line 73, in main\n",
            "    log_dict_train, _ = trainer.train(epoch, train_loader)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/trains/base_trainer.py\", line 119, in train\n",
            "    return self.run_epoch('train', epoch, data_loader)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/trains/base_trainer.py\", line 71, in run_epoch\n",
            "    output, loss, loss_stats = model_with_loss(batch)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/trains/base_trainer.py\", line 19, in forward\n",
            "    outputs = self.model(batch['input'])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/models/networks/pose_hrnet.py\", line 499, in forward\n",
            "    x = self.stage4(x_list)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 100, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/models/networks/pose_hrnet.py\", line 250, in forward\n",
            "    x[i] = self.branches[i](x[i])\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\", line 100, in forward\n",
            "    input = module(input)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/models/networks/pose_hrnet.py\", line 46, in forward\n",
            "    out = self.conv2(out)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\", line 550, in __call__\n",
            "    result = self.forward(*input, **kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 349, in forward\n",
            "    return self._conv_forward(input, self.weight)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\", line 346, in _conv_forward\n",
            "    self.padding, self.dilation, self.groups)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 11.17 GiB total capacity; 10.78 GiB already allocated; 11.81 MiB free; 10.85 GiB reserved in total by PyTorch)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpQInK8sQ-6G",
        "colab_type": "text"
      },
      "source": [
        "### Train with pre-trained weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEulOm5IYgfd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train with pretrained weights\n",
        "# !python train.py mot --exp_id all_hrnet --gpus '0' --batch_size 8 --reid_dim 128 --arch 'hrnet_18' --load_model ../models/all_hrnet_v2_w18.pth --num_epochs 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFmcTblYWJXu",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the network (tracking performance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aCvtBVuyWT4X"
      },
      "source": [
        "## Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "430cfdfc-efaf-457e-8683-f4bc1bcfd6b1",
        "id": "H2F0wrgTWVlX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# Install requirements\n",
        "# first change to the right folder\n",
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT')\n",
        "%pwd # print current location"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4_xPq67eWac_",
        "colab": {}
      },
      "source": [
        "# then install requirements\n",
        "!pip install -r requirements.txt\n",
        "# restart runtime when required"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v34B2iYSWh8i",
        "colab_type": "text"
      },
      "source": [
        "## Track"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6n-Fsw7QWhpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "c71c0d9c-0c65-44c1-febe-86545049b71c"
      },
      "source": [
        "import os\n",
        "os.chdir('/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src')\n",
        "%pwd # print current location"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD92uAc-W0UD",
        "colab_type": "text"
      },
      "source": [
        "### Pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TksUiWZBWk2h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ea4105cf-7edb-4cf3-b615-cd612f58724d"
      },
      "source": [
        "!python track.py mot --exp_id hrnet_pretrained --val_mot17 True --arch 'hrnet_18' --load_model ../models/all_hrnet_v2_w18.pth --conf_thres 0.4"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fix size testing.\n",
            "training chunk_sizes: [6, 6]\n",
            "The output will be saved to  /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/hrnet_pretrained\n",
            "heads {'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "2020-05-22 08:40:34 [INFO]: start seq: MOT17-02-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 08:40:46 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "2020-05-22 08:40:56 [INFO]: Processing frame 20 (16.77 fps)\n",
            "2020-05-22 08:41:05 [INFO]: Processing frame 40 (16.83 fps)\n",
            "2020-05-22 08:41:15 [INFO]: Processing frame 60 (16.80 fps)\n",
            "2020-05-22 08:41:26 [INFO]: Processing frame 80 (16.77 fps)\n",
            "2020-05-22 08:41:35 [INFO]: Processing frame 100 (16.63 fps)\n",
            "2020-05-22 08:41:46 [INFO]: Processing frame 120 (16.65 fps)\n",
            "2020-05-22 08:41:55 [INFO]: Processing frame 140 (16.62 fps)\n",
            "2020-05-22 08:42:08 [INFO]: Processing frame 160 (16.59 fps)\n",
            "2020-05-22 08:42:18 [INFO]: Processing frame 180 (16.56 fps)\n",
            "2020-05-22 08:42:29 [INFO]: Processing frame 200 (16.53 fps)\n",
            "2020-05-22 08:42:40 [INFO]: Processing frame 220 (16.53 fps)\n",
            "2020-05-22 08:42:49 [INFO]: Processing frame 240 (16.52 fps)\n",
            "2020-05-22 08:42:59 [INFO]: Processing frame 260 (16.52 fps)\n",
            "2020-05-22 08:43:09 [INFO]: Processing frame 280 (16.52 fps)\n",
            "2020-05-22 08:43:18 [INFO]: Processing frame 300 (16.51 fps)\n",
            "2020-05-22 08:43:44 [INFO]: Processing frame 320 (16.50 fps)\n",
            "2020-05-22 08:43:53 [INFO]: Processing frame 340 (16.49 fps)\n",
            "2020-05-22 08:44:02 [INFO]: Processing frame 360 (16.49 fps)\n",
            "2020-05-22 08:44:12 [INFO]: Processing frame 380 (16.49 fps)\n",
            "2020-05-22 08:44:22 [INFO]: Processing frame 400 (16.48 fps)\n",
            "2020-05-22 08:44:32 [INFO]: Processing frame 420 (16.48 fps)\n",
            "2020-05-22 08:44:41 [INFO]: Processing frame 440 (16.49 fps)\n",
            "2020-05-22 08:44:51 [INFO]: Processing frame 460 (16.49 fps)\n",
            "2020-05-22 08:45:00 [INFO]: Processing frame 480 (16.49 fps)\n",
            "2020-05-22 08:45:09 [INFO]: Processing frame 500 (16.48 fps)\n",
            "2020-05-22 08:45:18 [INFO]: Processing frame 520 (16.47 fps)\n",
            "2020-05-22 08:45:27 [INFO]: Processing frame 540 (16.47 fps)\n",
            "2020-05-22 08:45:36 [INFO]: Processing frame 560 (16.47 fps)\n",
            "2020-05-22 08:45:46 [INFO]: Processing frame 580 (16.47 fps)\n",
            "2020-05-22 08:45:54 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-02-SDP.txt\n",
            "2020-05-22 08:45:54 [INFO]: Evaluate seq: MOT17-02-SDP\n",
            "2020-05-22 08:45:56 [INFO]: start seq: MOT17-04-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 08:46:06 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 08:46:16 [INFO]: Processing frame 20 (15.97 fps)\n",
            "2020-05-22 08:46:27 [INFO]: Processing frame 40 (15.81 fps)\n",
            "2020-05-22 08:46:38 [INFO]: Processing frame 60 (15.75 fps)\n",
            "2020-05-22 08:46:48 [INFO]: Processing frame 80 (15.73 fps)\n",
            "2020-05-22 08:46:58 [INFO]: Processing frame 100 (15.72 fps)\n",
            "2020-05-22 08:47:08 [INFO]: Processing frame 120 (15.73 fps)\n",
            "2020-05-22 08:47:18 [INFO]: Processing frame 140 (15.74 fps)\n",
            "2020-05-22 08:47:27 [INFO]: Processing frame 160 (15.76 fps)\n",
            "2020-05-22 08:47:36 [INFO]: Processing frame 180 (15.73 fps)\n",
            "2020-05-22 08:47:46 [INFO]: Processing frame 200 (15.74 fps)\n",
            "2020-05-22 08:47:56 [INFO]: Processing frame 220 (15.74 fps)\n",
            "2020-05-22 08:48:05 [INFO]: Processing frame 240 (15.74 fps)\n",
            "2020-05-22 08:48:14 [INFO]: Processing frame 260 (15.72 fps)\n",
            "2020-05-22 08:48:24 [INFO]: Processing frame 280 (15.69 fps)\n",
            "2020-05-22 08:48:34 [INFO]: Processing frame 300 (15.66 fps)\n",
            "2020-05-22 08:48:45 [INFO]: Processing frame 320 (15.63 fps)\n",
            "2020-05-22 08:48:55 [INFO]: Processing frame 340 (15.60 fps)\n",
            "2020-05-22 08:49:05 [INFO]: Processing frame 360 (15.58 fps)\n",
            "2020-05-22 08:49:15 [INFO]: Processing frame 380 (15.57 fps)\n",
            "2020-05-22 08:49:26 [INFO]: Processing frame 400 (15.56 fps)\n",
            "2020-05-22 08:49:37 [INFO]: Processing frame 420 (15.54 fps)\n",
            "2020-05-22 08:49:47 [INFO]: Processing frame 440 (15.53 fps)\n",
            "2020-05-22 08:49:58 [INFO]: Processing frame 460 (15.51 fps)\n",
            "2020-05-22 08:50:09 [INFO]: Processing frame 480 (15.49 fps)\n",
            "2020-05-22 08:50:19 [INFO]: Processing frame 500 (15.48 fps)\n",
            "2020-05-22 08:50:30 [INFO]: Processing frame 520 (15.46 fps)\n",
            "2020-05-22 08:50:41 [INFO]: Processing frame 540 (15.45 fps)\n",
            "2020-05-22 08:50:52 [INFO]: Processing frame 560 (15.45 fps)\n",
            "2020-05-22 08:51:05 [INFO]: Processing frame 580 (15.44 fps)\n",
            "2020-05-22 08:51:16 [INFO]: Processing frame 600 (15.44 fps)\n",
            "2020-05-22 08:51:27 [INFO]: Processing frame 620 (15.43 fps)\n",
            "2020-05-22 08:51:37 [INFO]: Processing frame 640 (15.43 fps)\n",
            "2020-05-22 08:51:48 [INFO]: Processing frame 660 (15.42 fps)\n",
            "2020-05-22 08:51:58 [INFO]: Processing frame 680 (15.42 fps)\n",
            "2020-05-22 08:52:08 [INFO]: Processing frame 700 (15.42 fps)\n",
            "2020-05-22 08:52:18 [INFO]: Processing frame 720 (15.42 fps)\n",
            "2020-05-22 08:52:28 [INFO]: Processing frame 740 (15.43 fps)\n",
            "2020-05-22 08:52:39 [INFO]: Processing frame 760 (15.43 fps)\n",
            "2020-05-22 08:53:00 [INFO]: Processing frame 780 (15.43 fps)\n",
            "2020-05-22 08:53:10 [INFO]: Processing frame 800 (15.43 fps)\n",
            "2020-05-22 08:53:20 [INFO]: Processing frame 820 (15.43 fps)\n",
            "2020-05-22 08:53:30 [INFO]: Processing frame 840 (15.43 fps)\n",
            "2020-05-22 08:53:40 [INFO]: Processing frame 860 (15.43 fps)\n",
            "2020-05-22 08:53:50 [INFO]: Processing frame 880 (15.42 fps)\n",
            "2020-05-22 08:53:59 [INFO]: Processing frame 900 (15.41 fps)\n",
            "2020-05-22 08:54:09 [INFO]: Processing frame 920 (15.40 fps)\n",
            "2020-05-22 08:54:18 [INFO]: Processing frame 940 (15.40 fps)\n",
            "2020-05-22 08:54:28 [INFO]: Processing frame 960 (15.39 fps)\n",
            "2020-05-22 08:54:38 [INFO]: Processing frame 980 (15.39 fps)\n",
            "2020-05-22 08:54:48 [INFO]: Processing frame 1000 (15.38 fps)\n",
            "2020-05-22 08:54:59 [INFO]: Processing frame 1020 (15.38 fps)\n",
            "2020-05-22 08:55:09 [INFO]: Processing frame 1040 (15.37 fps)\n",
            "2020-05-22 08:55:15 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-04-SDP.txt\n",
            "2020-05-22 08:55:15 [INFO]: Evaluate seq: MOT17-04-SDP\n",
            "2020-05-22 08:55:18 [INFO]: start seq: MOT17-05-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 08:55:30 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 08:55:37 [INFO]: Processing frame 20 (17.82 fps)\n",
            "2020-05-22 08:55:45 [INFO]: Processing frame 40 (17.80 fps)\n",
            "2020-05-22 08:55:53 [INFO]: Processing frame 60 (17.84 fps)\n",
            "2020-05-22 08:56:00 [INFO]: Processing frame 80 (17.83 fps)\n",
            "2020-05-22 08:56:08 [INFO]: Processing frame 100 (17.61 fps)\n",
            "2020-05-22 08:56:15 [INFO]: Processing frame 120 (17.64 fps)\n",
            "2020-05-22 08:56:22 [INFO]: Processing frame 140 (17.48 fps)\n",
            "2020-05-22 08:56:30 [INFO]: Processing frame 160 (17.48 fps)\n",
            "2020-05-22 08:56:38 [INFO]: Processing frame 180 (17.51 fps)\n",
            "2020-05-22 08:56:45 [INFO]: Processing frame 200 (17.54 fps)\n",
            "2020-05-22 08:56:53 [INFO]: Processing frame 220 (17.56 fps)\n",
            "2020-05-22 08:57:01 [INFO]: Processing frame 240 (17.57 fps)\n",
            "2020-05-22 08:57:17 [INFO]: Processing frame 260 (17.56 fps)\n",
            "2020-05-22 08:57:24 [INFO]: Processing frame 280 (17.56 fps)\n",
            "2020-05-22 08:57:31 [INFO]: Processing frame 300 (17.56 fps)\n",
            "2020-05-22 08:57:39 [INFO]: Processing frame 320 (17.57 fps)\n",
            "2020-05-22 08:57:47 [INFO]: Processing frame 340 (17.57 fps)\n",
            "2020-05-22 08:57:55 [INFO]: Processing frame 360 (17.58 fps)\n",
            "2020-05-22 08:58:03 [INFO]: Processing frame 380 (17.58 fps)\n",
            "2020-05-22 08:58:14 [INFO]: Processing frame 400 (17.57 fps)\n",
            "2020-05-22 08:58:22 [INFO]: Processing frame 420 (17.57 fps)\n",
            "2020-05-22 08:58:30 [INFO]: Processing frame 440 (17.58 fps)\n",
            "2020-05-22 08:58:38 [INFO]: Processing frame 460 (17.57 fps)\n",
            "2020-05-22 08:58:45 [INFO]: Processing frame 480 (17.57 fps)\n",
            "2020-05-22 08:58:53 [INFO]: Processing frame 500 (17.57 fps)\n",
            "2020-05-22 08:59:01 [INFO]: Processing frame 520 (17.58 fps)\n",
            "2020-05-22 08:59:09 [INFO]: Processing frame 540 (17.57 fps)\n",
            "2020-05-22 08:59:17 [INFO]: Processing frame 560 (17.57 fps)\n",
            "2020-05-22 08:59:27 [INFO]: Processing frame 580 (17.58 fps)\n",
            "2020-05-22 08:59:35 [INFO]: Processing frame 600 (17.58 fps)\n",
            "2020-05-22 08:59:42 [INFO]: Processing frame 620 (17.60 fps)\n",
            "2020-05-22 08:59:50 [INFO]: Processing frame 640 (17.60 fps)\n",
            "2020-05-22 08:59:59 [INFO]: Processing frame 660 (17.60 fps)\n",
            "2020-05-22 09:00:07 [INFO]: Processing frame 680 (17.60 fps)\n",
            "2020-05-22 09:00:15 [INFO]: Processing frame 700 (17.60 fps)\n",
            "2020-05-22 09:00:23 [INFO]: Processing frame 720 (17.60 fps)\n",
            "2020-05-22 09:00:31 [INFO]: Processing frame 740 (17.60 fps)\n",
            "2020-05-22 09:00:39 [INFO]: Processing frame 760 (17.59 fps)\n",
            "2020-05-22 09:00:47 [INFO]: Processing frame 780 (17.58 fps)\n",
            "2020-05-22 09:00:55 [INFO]: Processing frame 800 (17.57 fps)\n",
            "2020-05-22 09:01:04 [INFO]: Processing frame 820 (17.56 fps)\n",
            "2020-05-22 09:01:10 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-05-SDP.txt\n",
            "2020-05-22 09:01:10 [INFO]: Evaluate seq: MOT17-05-SDP\n",
            "2020-05-22 09:01:11 [INFO]: start seq: MOT17-09-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:01:18 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:01:28 [INFO]: Processing frame 20 (17.65 fps)\n",
            "2020-05-22 09:01:36 [INFO]: Processing frame 40 (17.61 fps)\n",
            "2020-05-22 09:01:44 [INFO]: Processing frame 60 (17.52 fps)\n",
            "2020-05-22 09:01:53 [INFO]: Processing frame 80 (17.50 fps)\n",
            "2020-05-22 09:02:02 [INFO]: Processing frame 100 (17.53 fps)\n",
            "2020-05-22 09:02:11 [INFO]: Processing frame 120 (17.59 fps)\n",
            "2020-05-22 09:02:20 [INFO]: Processing frame 140 (17.64 fps)\n",
            "2020-05-22 09:02:29 [INFO]: Processing frame 160 (17.66 fps)\n",
            "2020-05-22 09:02:38 [INFO]: Processing frame 180 (17.66 fps)\n",
            "2020-05-22 09:02:47 [INFO]: Processing frame 200 (17.65 fps)\n",
            "2020-05-22 09:02:56 [INFO]: Processing frame 220 (17.64 fps)\n",
            "2020-05-22 09:03:04 [INFO]: Processing frame 240 (17.62 fps)\n",
            "2020-05-22 09:03:12 [INFO]: Processing frame 260 (17.60 fps)\n",
            "2020-05-22 09:03:21 [INFO]: Processing frame 280 (17.54 fps)\n",
            "2020-05-22 09:03:30 [INFO]: Processing frame 300 (17.54 fps)\n",
            "2020-05-22 09:03:38 [INFO]: Processing frame 320 (17.55 fps)\n",
            "2020-05-22 09:03:46 [INFO]: Processing frame 340 (17.55 fps)\n",
            "2020-05-22 09:03:54 [INFO]: Processing frame 360 (17.56 fps)\n",
            "2020-05-22 09:04:02 [INFO]: Processing frame 380 (17.56 fps)\n",
            "2020-05-22 09:04:10 [INFO]: Processing frame 400 (17.56 fps)\n",
            "2020-05-22 09:04:18 [INFO]: Processing frame 420 (17.57 fps)\n",
            "2020-05-22 09:04:26 [INFO]: Processing frame 440 (17.57 fps)\n",
            "2020-05-22 09:04:34 [INFO]: Processing frame 460 (17.58 fps)\n",
            "2020-05-22 09:04:41 [INFO]: Processing frame 480 (17.58 fps)\n",
            "2020-05-22 09:04:49 [INFO]: Processing frame 500 (17.58 fps)\n",
            "2020-05-22 09:04:57 [INFO]: Processing frame 520 (17.59 fps)\n",
            "2020-05-22 09:04:58 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-09-SDP.txt\n",
            "2020-05-22 09:04:58 [INFO]: Evaluate seq: MOT17-09-SDP\n",
            "2020-05-22 09:04:59 [INFO]: start seq: MOT17-10-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:05:08 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:05:17 [INFO]: Processing frame 20 (17.11 fps)\n",
            "2020-05-22 09:05:24 [INFO]: Processing frame 40 (16.96 fps)\n",
            "2020-05-22 09:05:32 [INFO]: Processing frame 60 (16.88 fps)\n",
            "2020-05-22 09:05:41 [INFO]: Processing frame 80 (16.93 fps)\n",
            "2020-05-22 09:05:50 [INFO]: Processing frame 100 (16.96 fps)\n",
            "2020-05-22 09:05:59 [INFO]: Processing frame 120 (17.01 fps)\n",
            "2020-05-22 09:06:07 [INFO]: Processing frame 140 (17.03 fps)\n",
            "2020-05-22 09:06:16 [INFO]: Processing frame 160 (17.02 fps)\n",
            "2020-05-22 09:06:24 [INFO]: Processing frame 180 (17.02 fps)\n",
            "2020-05-22 09:06:32 [INFO]: Processing frame 200 (17.02 fps)\n",
            "2020-05-22 09:06:40 [INFO]: Processing frame 220 (17.02 fps)\n",
            "2020-05-22 09:06:49 [INFO]: Processing frame 240 (17.01 fps)\n",
            "2020-05-22 09:06:58 [INFO]: Processing frame 260 (17.00 fps)\n",
            "2020-05-22 09:07:07 [INFO]: Processing frame 280 (16.98 fps)\n",
            "2020-05-22 09:07:15 [INFO]: Processing frame 300 (16.96 fps)\n",
            "2020-05-22 09:07:24 [INFO]: Processing frame 320 (16.94 fps)\n",
            "2020-05-22 09:07:32 [INFO]: Processing frame 340 (16.93 fps)\n",
            "2020-05-22 09:07:40 [INFO]: Processing frame 360 (16.93 fps)\n",
            "2020-05-22 09:07:48 [INFO]: Processing frame 380 (16.93 fps)\n",
            "2020-05-22 09:07:56 [INFO]: Processing frame 400 (16.94 fps)\n",
            "2020-05-22 09:08:04 [INFO]: Processing frame 420 (16.94 fps)\n",
            "2020-05-22 09:08:13 [INFO]: Processing frame 440 (16.95 fps)\n",
            "2020-05-22 09:08:20 [INFO]: Processing frame 460 (16.96 fps)\n",
            "2020-05-22 09:08:28 [INFO]: Processing frame 480 (16.96 fps)\n",
            "2020-05-22 09:08:36 [INFO]: Processing frame 500 (16.97 fps)\n",
            "2020-05-22 09:08:44 [INFO]: Processing frame 520 (16.98 fps)\n",
            "2020-05-22 09:08:52 [INFO]: Processing frame 540 (16.98 fps)\n",
            "2020-05-22 09:09:00 [INFO]: Processing frame 560 (16.98 fps)\n",
            "2020-05-22 09:09:09 [INFO]: Processing frame 580 (16.97 fps)\n",
            "2020-05-22 09:09:17 [INFO]: Processing frame 600 (16.97 fps)\n",
            "2020-05-22 09:09:24 [INFO]: Processing frame 620 (16.97 fps)\n",
            "2020-05-22 09:09:32 [INFO]: Processing frame 640 (16.98 fps)\n",
            "2020-05-22 09:09:38 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-10-SDP.txt\n",
            "2020-05-22 09:09:38 [INFO]: Evaluate seq: MOT17-10-SDP\n",
            "2020-05-22 09:09:39 [INFO]: start seq: MOT17-11-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:09:49 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:09:58 [INFO]: Processing frame 20 (17.07 fps)\n",
            "2020-05-22 09:10:07 [INFO]: Processing frame 40 (17.12 fps)\n",
            "2020-05-22 09:10:16 [INFO]: Processing frame 60 (17.06 fps)\n",
            "2020-05-22 09:10:24 [INFO]: Processing frame 80 (17.13 fps)\n",
            "2020-05-22 09:10:40 [INFO]: Processing frame 100 (17.09 fps)\n",
            "2020-05-22 09:10:48 [INFO]: Processing frame 120 (17.10 fps)\n",
            "2020-05-22 09:10:56 [INFO]: Processing frame 140 (17.11 fps)\n",
            "2020-05-22 09:11:05 [INFO]: Processing frame 160 (17.16 fps)\n",
            "2020-05-22 09:11:14 [INFO]: Processing frame 180 (17.21 fps)\n",
            "2020-05-22 09:11:22 [INFO]: Processing frame 200 (17.25 fps)\n",
            "2020-05-22 09:11:31 [INFO]: Processing frame 220 (17.29 fps)\n",
            "2020-05-22 09:11:40 [INFO]: Processing frame 240 (17.33 fps)\n",
            "2020-05-22 09:11:48 [INFO]: Processing frame 260 (17.34 fps)\n",
            "2020-05-22 09:11:56 [INFO]: Processing frame 280 (17.35 fps)\n",
            "2020-05-22 09:12:06 [INFO]: Processing frame 300 (17.37 fps)\n",
            "2020-05-22 09:12:14 [INFO]: Processing frame 320 (17.38 fps)\n",
            "2020-05-22 09:12:23 [INFO]: Processing frame 340 (17.40 fps)\n",
            "2020-05-22 09:12:31 [INFO]: Processing frame 360 (17.41 fps)\n",
            "2020-05-22 09:12:39 [INFO]: Processing frame 380 (17.43 fps)\n",
            "2020-05-22 09:12:48 [INFO]: Processing frame 400 (17.44 fps)\n",
            "2020-05-22 09:12:57 [INFO]: Processing frame 420 (17.46 fps)\n",
            "2020-05-22 09:13:05 [INFO]: Processing frame 440 (17.46 fps)\n",
            "2020-05-22 09:13:18 [INFO]: Processing frame 460 (17.45 fps)\n",
            "2020-05-22 09:13:27 [INFO]: Processing frame 480 (17.46 fps)\n",
            "2020-05-22 09:13:35 [INFO]: Processing frame 500 (17.46 fps)\n",
            "2020-05-22 09:13:44 [INFO]: Processing frame 520 (17.46 fps)\n",
            "2020-05-22 09:13:53 [INFO]: Processing frame 540 (17.46 fps)\n",
            "2020-05-22 09:14:02 [INFO]: Processing frame 560 (17.47 fps)\n",
            "2020-05-22 09:14:11 [INFO]: Processing frame 580 (17.48 fps)\n",
            "2020-05-22 09:14:19 [INFO]: Processing frame 600 (17.48 fps)\n",
            "2020-05-22 09:14:28 [INFO]: Processing frame 620 (17.49 fps)\n",
            "2020-05-22 09:14:38 [INFO]: Processing frame 640 (17.49 fps)\n",
            "2020-05-22 09:14:46 [INFO]: Processing frame 660 (17.49 fps)\n",
            "2020-05-22 09:14:55 [INFO]: Processing frame 680 (17.50 fps)\n",
            "2020-05-22 09:15:04 [INFO]: Processing frame 700 (17.50 fps)\n",
            "2020-05-22 09:15:12 [INFO]: Processing frame 720 (17.50 fps)\n",
            "2020-05-22 09:15:20 [INFO]: Processing frame 740 (17.51 fps)\n",
            "2020-05-22 09:15:29 [INFO]: Processing frame 760 (17.51 fps)\n",
            "2020-05-22 09:15:38 [INFO]: Processing frame 780 (17.52 fps)\n",
            "2020-05-22 09:15:46 [INFO]: Processing frame 800 (17.51 fps)\n",
            "2020-05-22 09:15:55 [INFO]: Processing frame 820 (17.51 fps)\n",
            "2020-05-22 09:16:03 [INFO]: Processing frame 840 (17.52 fps)\n",
            "2020-05-22 09:16:12 [INFO]: Processing frame 860 (17.51 fps)\n",
            "2020-05-22 09:16:22 [INFO]: Processing frame 880 (17.51 fps)\n",
            "2020-05-22 09:16:30 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-11-SDP.txt\n",
            "2020-05-22 09:16:30 [INFO]: Evaluate seq: MOT17-11-SDP\n",
            "2020-05-22 09:16:31 [INFO]: start seq: MOT17-13-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../models/all_hrnet_v2_w18.pth, epoch 60\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:16:40 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:16:51 [INFO]: Processing frame 20 (16.86 fps)\n",
            "2020-05-22 09:16:59 [INFO]: Processing frame 40 (16.60 fps)\n",
            "2020-05-22 09:17:08 [INFO]: Processing frame 60 (16.50 fps)\n",
            "2020-05-22 09:17:18 [INFO]: Processing frame 80 (16.44 fps)\n",
            "2020-05-22 09:17:28 [INFO]: Processing frame 100 (16.38 fps)\n",
            "2020-05-22 09:17:37 [INFO]: Processing frame 120 (16.37 fps)\n",
            "2020-05-22 09:17:48 [INFO]: Processing frame 140 (16.37 fps)\n",
            "2020-05-22 09:17:57 [INFO]: Processing frame 160 (16.40 fps)\n",
            "2020-05-22 09:18:06 [INFO]: Processing frame 180 (16.44 fps)\n",
            "2020-05-22 09:18:15 [INFO]: Processing frame 200 (16.49 fps)\n",
            "2020-05-22 09:18:23 [INFO]: Processing frame 220 (16.51 fps)\n",
            "2020-05-22 09:18:32 [INFO]: Processing frame 240 (16.53 fps)\n",
            "2020-05-22 09:18:40 [INFO]: Processing frame 260 (16.57 fps)\n",
            "2020-05-22 09:18:49 [INFO]: Processing frame 280 (16.61 fps)\n",
            "2020-05-22 09:18:58 [INFO]: Processing frame 300 (16.64 fps)\n",
            "2020-05-22 09:19:07 [INFO]: Processing frame 320 (16.63 fps)\n",
            "2020-05-22 09:19:16 [INFO]: Processing frame 340 (16.62 fps)\n",
            "2020-05-22 09:19:25 [INFO]: Processing frame 360 (16.62 fps)\n",
            "2020-05-22 09:19:34 [INFO]: Processing frame 380 (16.63 fps)\n",
            "2020-05-22 09:19:43 [INFO]: Processing frame 400 (16.64 fps)\n",
            "2020-05-22 09:19:51 [INFO]: Processing frame 420 (16.65 fps)\n",
            "2020-05-22 09:19:59 [INFO]: Processing frame 440 (16.67 fps)\n",
            "2020-05-22 09:20:09 [INFO]: Processing frame 460 (16.69 fps)\n",
            "2020-05-22 09:20:18 [INFO]: Processing frame 480 (16.72 fps)\n",
            "2020-05-22 09:20:27 [INFO]: Processing frame 500 (16.76 fps)\n",
            "2020-05-22 09:20:35 [INFO]: Processing frame 520 (16.80 fps)\n",
            "2020-05-22 09:20:44 [INFO]: Processing frame 540 (16.83 fps)\n",
            "2020-05-22 09:20:53 [INFO]: Processing frame 560 (16.87 fps)\n",
            "2020-05-22 09:21:01 [INFO]: Processing frame 580 (16.90 fps)\n",
            "2020-05-22 09:21:10 [INFO]: Processing frame 600 (16.93 fps)\n",
            "2020-05-22 09:21:19 [INFO]: Processing frame 620 (16.95 fps)\n",
            "2020-05-22 09:21:27 [INFO]: Processing frame 640 (16.98 fps)\n",
            "2020-05-22 09:21:36 [INFO]: Processing frame 660 (17.00 fps)\n",
            "2020-05-22 09:21:46 [INFO]: Processing frame 680 (17.02 fps)\n",
            "2020-05-22 09:21:56 [INFO]: Processing frame 700 (17.04 fps)\n",
            "2020-05-22 09:22:05 [INFO]: Processing frame 720 (17.06 fps)\n",
            "2020-05-22 09:22:13 [INFO]: Processing frame 740 (17.08 fps)\n",
            "2020-05-22 09:22:17 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_pretrained/MOT17-13-SDP.txt\n",
            "2020-05-22 09:22:18 [INFO]: Evaluate seq: MOT17-13-SDP\n",
            "2020-05-22 09:22:18 [INFO]: Time elapsed: 316.10 seconds, FPS: 16.82\n",
            "              IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML   FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
            "MOT17-02-SDP 62.3% 71.0% 55.5% 76.0% 97.1%  62  27  28  7  420  4468 144   588 72.9% 0.180 108  28  16\n",
            "MOT17-04-SDP 87.1% 89.3% 85.0% 86.9% 91.3%  83  53  19 11 3956  6212  20   137 78.6% 0.158   6  10   2\n",
            "MOT17-05-SDP 76.8% 81.7% 72.4% 87.1% 98.3% 133  81  47  5  102   891  44   165 85.0% 0.189  75  13  50\n",
            "MOT17-09-SDP 59.1% 64.4% 54.6% 81.9% 96.6%  26  18   8  0  152   963  37    98 78.4% 0.151  34   6   8\n",
            "MOT17-10-SDP 68.5% 74.4% 63.5% 82.3% 96.3%  57  34  22  1  403  2275 108   368 78.3% 0.203  71  33  17\n",
            "MOT17-11-SDP 80.7% 82.2% 79.3% 93.7% 97.0%  75  61  11  3  270   594  17    78 90.7% 0.149  28   6  21\n",
            "MOT17-13-SDP 77.5% 80.6% 74.6% 88.9% 96.1% 110  86  18  6  416  1288  76   246 84.7% 0.192  62  25  36\n",
            "OVERALL      77.7% 81.9% 73.9% 85.1% 94.4% 546 360 153 33 5719 16691 446  1680 79.6% 0.171 384 121 150\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnX6hMPsW39J",
        "colab_type": "text"
      },
      "source": [
        "### Model trained from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt9y8Wa0W3t5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b39a473-b030-4e71-aced-7240939cf616"
      },
      "source": [
        "!python track.py mot --exp_id hrnet_scratchtrained20 --val_mot17 True --arch 'hrnet_18' --load_model ../exp/mot/all_hrnet/BS8_scratch/model_20.pth --conf_thres 0.4"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fix size testing.\n",
            "training chunk_sizes: [6, 6]\n",
            "The output will be saved to  /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/Github_5AUA0_Project_G12T1/FairMOT/src/lib/../../exp/mot/hrnet_scratchtrained\n",
            "heads {'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "2020-05-22 09:23:25 [INFO]: start seq: MOT17-02-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:23:31 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n",
            "2020-05-22 09:23:33 [INFO]: Processing frame 20 (17.69 fps)\n",
            "2020-05-22 09:23:35 [INFO]: Processing frame 40 (17.72 fps)\n",
            "2020-05-22 09:23:37 [INFO]: Processing frame 60 (17.55 fps)\n",
            "2020-05-22 09:23:39 [INFO]: Processing frame 80 (17.44 fps)\n",
            "2020-05-22 09:23:41 [INFO]: Processing frame 100 (17.46 fps)\n",
            "2020-05-22 09:23:43 [INFO]: Processing frame 120 (17.49 fps)\n",
            "2020-05-22 09:23:45 [INFO]: Processing frame 140 (17.45 fps)\n",
            "2020-05-22 09:23:47 [INFO]: Processing frame 160 (17.43 fps)\n",
            "2020-05-22 09:23:49 [INFO]: Processing frame 180 (17.41 fps)\n",
            "2020-05-22 09:23:51 [INFO]: Processing frame 200 (17.40 fps)\n",
            "2020-05-22 09:23:53 [INFO]: Processing frame 220 (17.37 fps)\n",
            "2020-05-22 09:23:55 [INFO]: Processing frame 240 (17.35 fps)\n",
            "2020-05-22 09:23:57 [INFO]: Processing frame 260 (17.32 fps)\n",
            "2020-05-22 09:23:59 [INFO]: Processing frame 280 (17.32 fps)\n",
            "2020-05-22 09:24:01 [INFO]: Processing frame 300 (17.30 fps)\n",
            "2020-05-22 09:24:03 [INFO]: Processing frame 320 (17.30 fps)\n",
            "2020-05-22 09:24:05 [INFO]: Processing frame 340 (17.30 fps)\n",
            "2020-05-22 09:24:07 [INFO]: Processing frame 360 (17.30 fps)\n",
            "2020-05-22 09:24:09 [INFO]: Processing frame 380 (17.31 fps)\n",
            "2020-05-22 09:24:11 [INFO]: Processing frame 400 (17.31 fps)\n",
            "2020-05-22 09:24:14 [INFO]: Processing frame 420 (17.30 fps)\n",
            "2020-05-22 09:24:16 [INFO]: Processing frame 440 (17.28 fps)\n",
            "2020-05-22 09:24:18 [INFO]: Processing frame 460 (17.28 fps)\n",
            "2020-05-22 09:24:20 [INFO]: Processing frame 480 (17.29 fps)\n",
            "2020-05-22 09:24:22 [INFO]: Processing frame 500 (17.28 fps)\n",
            "2020-05-22 09:24:24 [INFO]: Processing frame 520 (17.29 fps)\n",
            "2020-05-22 09:24:26 [INFO]: Processing frame 540 (17.29 fps)\n",
            "2020-05-22 09:24:28 [INFO]: Processing frame 560 (17.29 fps)\n",
            "2020-05-22 09:24:30 [INFO]: Processing frame 580 (17.29 fps)\n",
            "2020-05-22 09:24:32 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-02-SDP.txt\n",
            "2020-05-22 09:24:32 [INFO]: Evaluate seq: MOT17-02-SDP\n",
            "2020-05-22 09:24:33 [INFO]: start seq: MOT17-04-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:24:34 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:24:36 [INFO]: Processing frame 20 (16.61 fps)\n",
            "2020-05-22 09:24:38 [INFO]: Processing frame 40 (16.54 fps)\n",
            "2020-05-22 09:24:40 [INFO]: Processing frame 60 (16.54 fps)\n",
            "2020-05-22 09:24:42 [INFO]: Processing frame 80 (16.55 fps)\n",
            "2020-05-22 09:24:45 [INFO]: Processing frame 100 (16.52 fps)\n",
            "2020-05-22 09:24:47 [INFO]: Processing frame 120 (16.49 fps)\n",
            "2020-05-22 09:24:49 [INFO]: Processing frame 140 (16.49 fps)\n",
            "2020-05-22 09:24:51 [INFO]: Processing frame 160 (16.46 fps)\n",
            "2020-05-22 09:24:53 [INFO]: Processing frame 180 (16.47 fps)\n",
            "2020-05-22 09:24:55 [INFO]: Processing frame 200 (16.47 fps)\n",
            "2020-05-22 09:24:58 [INFO]: Processing frame 220 (16.46 fps)\n",
            "2020-05-22 09:25:00 [INFO]: Processing frame 240 (16.47 fps)\n",
            "2020-05-22 09:25:02 [INFO]: Processing frame 260 (16.46 fps)\n",
            "2020-05-22 09:25:04 [INFO]: Processing frame 280 (16.44 fps)\n",
            "2020-05-22 09:25:06 [INFO]: Processing frame 300 (16.41 fps)\n",
            "2020-05-22 09:25:08 [INFO]: Processing frame 320 (16.40 fps)\n",
            "2020-05-22 09:25:11 [INFO]: Processing frame 340 (16.37 fps)\n",
            "2020-05-22 09:25:13 [INFO]: Processing frame 360 (16.35 fps)\n",
            "2020-05-22 09:25:15 [INFO]: Processing frame 380 (16.33 fps)\n",
            "2020-05-22 09:25:17 [INFO]: Processing frame 400 (16.30 fps)\n",
            "2020-05-22 09:25:19 [INFO]: Processing frame 420 (16.28 fps)\n",
            "2020-05-22 09:25:22 [INFO]: Processing frame 440 (16.26 fps)\n",
            "2020-05-22 09:25:24 [INFO]: Processing frame 460 (16.25 fps)\n",
            "2020-05-22 09:25:26 [INFO]: Processing frame 480 (16.23 fps)\n",
            "2020-05-22 09:25:28 [INFO]: Processing frame 500 (16.21 fps)\n",
            "2020-05-22 09:25:30 [INFO]: Processing frame 520 (16.20 fps)\n",
            "2020-05-22 09:25:32 [INFO]: Processing frame 540 (16.19 fps)\n",
            "2020-05-22 09:25:35 [INFO]: Processing frame 560 (16.18 fps)\n",
            "2020-05-22 09:25:37 [INFO]: Processing frame 580 (16.18 fps)\n",
            "2020-05-22 09:25:39 [INFO]: Processing frame 600 (16.18 fps)\n",
            "2020-05-22 09:25:41 [INFO]: Processing frame 620 (16.18 fps)\n",
            "2020-05-22 09:25:43 [INFO]: Processing frame 640 (16.18 fps)\n",
            "2020-05-22 09:25:45 [INFO]: Processing frame 660 (16.18 fps)\n",
            "2020-05-22 09:25:48 [INFO]: Processing frame 680 (16.18 fps)\n",
            "2020-05-22 09:25:50 [INFO]: Processing frame 700 (16.18 fps)\n",
            "2020-05-22 09:25:52 [INFO]: Processing frame 720 (16.17 fps)\n",
            "2020-05-22 09:25:54 [INFO]: Processing frame 740 (16.18 fps)\n",
            "2020-05-22 09:25:56 [INFO]: Processing frame 760 (16.18 fps)\n",
            "2020-05-22 09:25:59 [INFO]: Processing frame 780 (16.17 fps)\n",
            "2020-05-22 09:26:01 [INFO]: Processing frame 800 (16.17 fps)\n",
            "2020-05-22 09:26:03 [INFO]: Processing frame 820 (16.17 fps)\n",
            "2020-05-22 09:26:05 [INFO]: Processing frame 840 (16.17 fps)\n",
            "2020-05-22 09:26:07 [INFO]: Processing frame 860 (16.17 fps)\n",
            "2020-05-22 09:26:10 [INFO]: Processing frame 880 (16.16 fps)\n",
            "2020-05-22 09:26:12 [INFO]: Processing frame 900 (16.15 fps)\n",
            "2020-05-22 09:26:14 [INFO]: Processing frame 920 (16.14 fps)\n",
            "2020-05-22 09:26:16 [INFO]: Processing frame 940 (16.14 fps)\n",
            "2020-05-22 09:26:18 [INFO]: Processing frame 960 (16.14 fps)\n",
            "2020-05-22 09:26:21 [INFO]: Processing frame 980 (16.12 fps)\n",
            "2020-05-22 09:26:23 [INFO]: Processing frame 1000 (16.12 fps)\n",
            "2020-05-22 09:26:25 [INFO]: Processing frame 1020 (16.11 fps)\n",
            "2020-05-22 09:26:27 [INFO]: Processing frame 1040 (16.10 fps)\n",
            "2020-05-22 09:26:29 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-04-SDP.txt\n",
            "2020-05-22 09:26:29 [INFO]: Evaluate seq: MOT17-04-SDP\n",
            "2020-05-22 09:26:31 [INFO]: start seq: MOT17-05-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:26:32 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:26:33 [INFO]: Processing frame 20 (18.18 fps)\n",
            "2020-05-22 09:26:35 [INFO]: Processing frame 40 (18.42 fps)\n",
            "2020-05-22 09:26:36 [INFO]: Processing frame 60 (18.59 fps)\n",
            "2020-05-22 09:26:37 [INFO]: Processing frame 80 (18.72 fps)\n",
            "2020-05-22 09:26:39 [INFO]: Processing frame 100 (18.72 fps)\n",
            "2020-05-22 09:26:40 [INFO]: Processing frame 120 (18.67 fps)\n",
            "2020-05-22 09:26:41 [INFO]: Processing frame 140 (18.69 fps)\n",
            "2020-05-22 09:26:43 [INFO]: Processing frame 160 (18.72 fps)\n",
            "2020-05-22 09:26:44 [INFO]: Processing frame 180 (18.75 fps)\n",
            "2020-05-22 09:26:45 [INFO]: Processing frame 200 (18.78 fps)\n",
            "2020-05-22 09:26:46 [INFO]: Processing frame 220 (18.78 fps)\n",
            "2020-05-22 09:26:48 [INFO]: Processing frame 240 (18.79 fps)\n",
            "2020-05-22 09:26:49 [INFO]: Processing frame 260 (18.78 fps)\n",
            "2020-05-22 09:26:50 [INFO]: Processing frame 280 (18.78 fps)\n",
            "2020-05-22 09:26:52 [INFO]: Processing frame 300 (18.77 fps)\n",
            "2020-05-22 09:26:53 [INFO]: Processing frame 320 (18.75 fps)\n",
            "2020-05-22 09:26:55 [INFO]: Processing frame 340 (18.76 fps)\n",
            "2020-05-22 09:26:56 [INFO]: Processing frame 360 (18.76 fps)\n",
            "2020-05-22 09:26:57 [INFO]: Processing frame 380 (18.78 fps)\n",
            "2020-05-22 09:26:58 [INFO]: Processing frame 400 (18.78 fps)\n",
            "2020-05-22 09:27:00 [INFO]: Processing frame 420 (18.79 fps)\n",
            "2020-05-22 09:27:01 [INFO]: Processing frame 440 (18.79 fps)\n",
            "2020-05-22 09:27:02 [INFO]: Processing frame 460 (18.78 fps)\n",
            "2020-05-22 09:27:04 [INFO]: Processing frame 480 (18.79 fps)\n",
            "2020-05-22 09:27:05 [INFO]: Processing frame 500 (18.80 fps)\n",
            "2020-05-22 09:27:06 [INFO]: Processing frame 520 (18.81 fps)\n",
            "2020-05-22 09:27:08 [INFO]: Processing frame 540 (18.82 fps)\n",
            "2020-05-22 09:27:09 [INFO]: Processing frame 560 (18.82 fps)\n",
            "2020-05-22 09:27:10 [INFO]: Processing frame 580 (18.82 fps)\n",
            "2020-05-22 09:27:12 [INFO]: Processing frame 600 (18.83 fps)\n",
            "2020-05-22 09:27:13 [INFO]: Processing frame 620 (18.84 fps)\n",
            "2020-05-22 09:27:14 [INFO]: Processing frame 640 (18.84 fps)\n",
            "2020-05-22 09:27:16 [INFO]: Processing frame 660 (18.85 fps)\n",
            "2020-05-22 09:27:17 [INFO]: Processing frame 680 (18.85 fps)\n",
            "2020-05-22 09:27:18 [INFO]: Processing frame 700 (18.85 fps)\n",
            "2020-05-22 09:27:20 [INFO]: Processing frame 720 (18.85 fps)\n",
            "2020-05-22 09:27:21 [INFO]: Processing frame 740 (18.84 fps)\n",
            "2020-05-22 09:27:22 [INFO]: Processing frame 760 (18.84 fps)\n",
            "2020-05-22 09:27:24 [INFO]: Processing frame 780 (18.83 fps)\n",
            "2020-05-22 09:27:25 [INFO]: Processing frame 800 (18.82 fps)\n",
            "2020-05-22 09:27:26 [INFO]: Processing frame 820 (18.81 fps)\n",
            "2020-05-22 09:27:28 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-05-SDP.txt\n",
            "2020-05-22 09:27:28 [INFO]: Evaluate seq: MOT17-05-SDP\n",
            "2020-05-22 09:27:28 [INFO]: start seq: MOT17-09-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:27:29 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:27:31 [INFO]: Processing frame 20 (18.62 fps)\n",
            "2020-05-22 09:27:33 [INFO]: Processing frame 40 (18.71 fps)\n",
            "2020-05-22 09:27:35 [INFO]: Processing frame 60 (18.70 fps)\n",
            "2020-05-22 09:27:37 [INFO]: Processing frame 80 (18.75 fps)\n",
            "2020-05-22 09:27:39 [INFO]: Processing frame 100 (18.78 fps)\n",
            "2020-05-22 09:27:41 [INFO]: Processing frame 120 (18.76 fps)\n",
            "2020-05-22 09:27:43 [INFO]: Processing frame 140 (18.80 fps)\n",
            "2020-05-22 09:27:45 [INFO]: Processing frame 160 (18.77 fps)\n",
            "2020-05-22 09:27:47 [INFO]: Processing frame 180 (18.76 fps)\n",
            "2020-05-22 09:27:49 [INFO]: Processing frame 200 (18.73 fps)\n",
            "2020-05-22 09:27:51 [INFO]: Processing frame 220 (18.71 fps)\n",
            "2020-05-22 09:27:53 [INFO]: Processing frame 240 (18.67 fps)\n",
            "2020-05-22 09:27:55 [INFO]: Processing frame 260 (18.65 fps)\n",
            "2020-05-22 09:27:57 [INFO]: Processing frame 280 (18.66 fps)\n",
            "2020-05-22 09:27:59 [INFO]: Processing frame 300 (18.66 fps)\n",
            "2020-05-22 09:28:01 [INFO]: Processing frame 320 (18.67 fps)\n",
            "2020-05-22 09:28:03 [INFO]: Processing frame 340 (18.66 fps)\n",
            "2020-05-22 09:28:05 [INFO]: Processing frame 360 (18.66 fps)\n",
            "2020-05-22 09:28:07 [INFO]: Processing frame 380 (18.66 fps)\n",
            "2020-05-22 09:28:09 [INFO]: Processing frame 400 (18.67 fps)\n",
            "2020-05-22 09:28:11 [INFO]: Processing frame 420 (18.67 fps)\n",
            "2020-05-22 09:28:13 [INFO]: Processing frame 440 (18.67 fps)\n",
            "2020-05-22 09:28:15 [INFO]: Processing frame 460 (18.67 fps)\n",
            "2020-05-22 09:28:17 [INFO]: Processing frame 480 (18.68 fps)\n",
            "2020-05-22 09:28:19 [INFO]: Processing frame 500 (18.67 fps)\n",
            "2020-05-22 09:28:21 [INFO]: Processing frame 520 (18.67 fps)\n",
            "2020-05-22 09:28:22 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-09-SDP.txt\n",
            "2020-05-22 09:28:22 [INFO]: Evaluate seq: MOT17-09-SDP\n",
            "2020-05-22 09:28:22 [INFO]: start seq: MOT17-10-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:28:23 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:28:25 [INFO]: Processing frame 20 (17.95 fps)\n",
            "2020-05-22 09:28:27 [INFO]: Processing frame 40 (17.97 fps)\n",
            "2020-05-22 09:28:29 [INFO]: Processing frame 60 (17.87 fps)\n",
            "2020-05-22 09:28:31 [INFO]: Processing frame 80 (17.96 fps)\n",
            "2020-05-22 09:28:33 [INFO]: Processing frame 100 (18.00 fps)\n",
            "2020-05-22 09:28:35 [INFO]: Processing frame 120 (18.06 fps)\n",
            "2020-05-22 09:28:37 [INFO]: Processing frame 140 (18.07 fps)\n",
            "2020-05-22 09:28:39 [INFO]: Processing frame 160 (18.08 fps)\n",
            "2020-05-22 09:28:41 [INFO]: Processing frame 180 (18.05 fps)\n",
            "2020-05-22 09:28:43 [INFO]: Processing frame 200 (18.05 fps)\n",
            "2020-05-22 09:28:45 [INFO]: Processing frame 220 (18.03 fps)\n",
            "2020-05-22 09:28:47 [INFO]: Processing frame 240 (18.01 fps)\n",
            "2020-05-22 09:28:49 [INFO]: Processing frame 260 (17.99 fps)\n",
            "2020-05-22 09:28:51 [INFO]: Processing frame 280 (17.97 fps)\n",
            "2020-05-22 09:28:53 [INFO]: Processing frame 300 (17.93 fps)\n",
            "2020-05-22 09:28:55 [INFO]: Processing frame 320 (17.90 fps)\n",
            "2020-05-22 09:28:57 [INFO]: Processing frame 340 (17.89 fps)\n",
            "2020-05-22 09:28:59 [INFO]: Processing frame 360 (17.90 fps)\n",
            "2020-05-22 09:29:01 [INFO]: Processing frame 380 (17.89 fps)\n",
            "2020-05-22 09:29:03 [INFO]: Processing frame 400 (17.88 fps)\n",
            "2020-05-22 09:29:05 [INFO]: Processing frame 420 (17.89 fps)\n",
            "2020-05-22 09:29:07 [INFO]: Processing frame 440 (17.88 fps)\n",
            "2020-05-22 09:29:09 [INFO]: Processing frame 460 (17.87 fps)\n",
            "2020-05-22 09:29:11 [INFO]: Processing frame 480 (17.88 fps)\n",
            "2020-05-22 09:29:13 [INFO]: Processing frame 500 (17.89 fps)\n",
            "2020-05-22 09:29:15 [INFO]: Processing frame 520 (17.90 fps)\n",
            "2020-05-22 09:29:17 [INFO]: Processing frame 540 (17.92 fps)\n",
            "2020-05-22 09:29:19 [INFO]: Processing frame 560 (17.92 fps)\n",
            "2020-05-22 09:29:21 [INFO]: Processing frame 580 (17.92 fps)\n",
            "2020-05-22 09:29:23 [INFO]: Processing frame 600 (17.92 fps)\n",
            "2020-05-22 09:29:25 [INFO]: Processing frame 620 (17.93 fps)\n",
            "2020-05-22 09:29:27 [INFO]: Processing frame 640 (17.94 fps)\n",
            "2020-05-22 09:29:29 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-10-SDP.txt\n",
            "2020-05-22 09:29:29 [INFO]: Evaluate seq: MOT17-10-SDP\n",
            "2020-05-22 09:29:29 [INFO]: start seq: MOT17-11-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:29:31 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:29:33 [INFO]: Processing frame 20 (18.41 fps)\n",
            "2020-05-22 09:29:35 [INFO]: Processing frame 40 (18.23 fps)\n",
            "2020-05-22 09:29:37 [INFO]: Processing frame 60 (18.26 fps)\n",
            "2020-05-22 09:29:39 [INFO]: Processing frame 80 (18.32 fps)\n",
            "2020-05-22 09:29:41 [INFO]: Processing frame 100 (18.29 fps)\n",
            "2020-05-22 09:29:43 [INFO]: Processing frame 120 (18.30 fps)\n",
            "2020-05-22 09:29:45 [INFO]: Processing frame 140 (18.33 fps)\n",
            "2020-05-22 09:29:46 [INFO]: Processing frame 160 (18.36 fps)\n",
            "2020-05-22 09:29:48 [INFO]: Processing frame 180 (18.41 fps)\n",
            "2020-05-22 09:29:50 [INFO]: Processing frame 200 (18.43 fps)\n",
            "2020-05-22 09:29:52 [INFO]: Processing frame 220 (18.46 fps)\n",
            "2020-05-22 09:29:54 [INFO]: Processing frame 240 (18.48 fps)\n",
            "2020-05-22 09:29:56 [INFO]: Processing frame 260 (18.48 fps)\n",
            "2020-05-22 09:29:58 [INFO]: Processing frame 280 (18.46 fps)\n",
            "2020-05-22 09:30:00 [INFO]: Processing frame 300 (18.47 fps)\n",
            "2020-05-22 09:30:02 [INFO]: Processing frame 320 (18.49 fps)\n",
            "2020-05-22 09:30:04 [INFO]: Processing frame 340 (18.48 fps)\n",
            "2020-05-22 09:30:06 [INFO]: Processing frame 360 (18.50 fps)\n",
            "2020-05-22 09:30:08 [INFO]: Processing frame 380 (18.50 fps)\n",
            "2020-05-22 09:30:10 [INFO]: Processing frame 400 (18.51 fps)\n",
            "2020-05-22 09:30:12 [INFO]: Processing frame 420 (18.51 fps)\n",
            "2020-05-22 09:30:14 [INFO]: Processing frame 440 (18.51 fps)\n",
            "2020-05-22 09:30:16 [INFO]: Processing frame 460 (18.52 fps)\n",
            "2020-05-22 09:30:18 [INFO]: Processing frame 480 (18.53 fps)\n",
            "2020-05-22 09:30:20 [INFO]: Processing frame 500 (18.53 fps)\n",
            "2020-05-22 09:30:22 [INFO]: Processing frame 520 (18.53 fps)\n",
            "2020-05-22 09:30:24 [INFO]: Processing frame 540 (18.54 fps)\n",
            "2020-05-22 09:30:26 [INFO]: Processing frame 560 (18.55 fps)\n",
            "2020-05-22 09:30:28 [INFO]: Processing frame 580 (18.56 fps)\n",
            "2020-05-22 09:30:30 [INFO]: Processing frame 600 (18.56 fps)\n",
            "2020-05-22 09:30:32 [INFO]: Processing frame 620 (18.57 fps)\n",
            "2020-05-22 09:30:34 [INFO]: Processing frame 640 (18.58 fps)\n",
            "2020-05-22 09:30:36 [INFO]: Processing frame 660 (18.58 fps)\n",
            "2020-05-22 09:30:37 [INFO]: Processing frame 680 (18.58 fps)\n",
            "2020-05-22 09:30:39 [INFO]: Processing frame 700 (18.58 fps)\n",
            "2020-05-22 09:30:41 [INFO]: Processing frame 720 (18.58 fps)\n",
            "2020-05-22 09:30:43 [INFO]: Processing frame 740 (18.59 fps)\n",
            "2020-05-22 09:30:45 [INFO]: Processing frame 760 (18.59 fps)\n",
            "2020-05-22 09:30:47 [INFO]: Processing frame 780 (18.60 fps)\n",
            "2020-05-22 09:30:49 [INFO]: Processing frame 800 (18.59 fps)\n",
            "2020-05-22 09:30:51 [INFO]: Processing frame 820 (18.60 fps)\n",
            "2020-05-22 09:30:53 [INFO]: Processing frame 840 (18.60 fps)\n",
            "2020-05-22 09:30:55 [INFO]: Processing frame 860 (18.59 fps)\n",
            "2020-05-22 09:30:57 [INFO]: Processing frame 880 (18.58 fps)\n",
            "2020-05-22 09:30:59 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-11-SDP.txt\n",
            "2020-05-22 09:30:59 [INFO]: Evaluate seq: MOT17-11-SDP\n",
            "2020-05-22 09:31:00 [INFO]: start seq: MOT17-13-SDP\n",
            "Creating model...\n",
            "{'hm': 1, 'wh': 2, 'id': 512, 'reg': 2}\n",
            "loaded ../exp/mot/all_hrnet/BS8_scratch/model_20.pth, epoch 20\n",
            "Skip loading parameter id.2.weight, required shapetorch.Size([512, 256, 1, 1]), loaded shapetorch.Size([128, 256, 1, 1]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "Skip loading parameter id.2.bias, required shapetorch.Size([512]), loaded shapetorch.Size([128]). If you see this, your model does not fully load the pre-trained weight. Please make sure you have correctly specified --arch xxx or set the correct --num_classes for your own dataset.\n",
            "2020-05-22 09:31:01 [INFO]: Processing frame 0 (100000.00 fps)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2796: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "2020-05-22 09:31:03 [INFO]: Processing frame 20 (17.12 fps)\n",
            "2020-05-22 09:31:05 [INFO]: Processing frame 40 (17.12 fps)\n",
            "2020-05-22 09:31:07 [INFO]: Processing frame 60 (17.17 fps)\n",
            "2020-05-22 09:31:09 [INFO]: Processing frame 80 (17.17 fps)\n",
            "2020-05-22 09:31:12 [INFO]: Processing frame 100 (17.21 fps)\n",
            "2020-05-22 09:31:14 [INFO]: Processing frame 120 (17.21 fps)\n",
            "2020-05-22 09:31:16 [INFO]: Processing frame 140 (17.19 fps)\n",
            "2020-05-22 09:31:18 [INFO]: Processing frame 160 (17.24 fps)\n",
            "2020-05-22 09:31:20 [INFO]: Processing frame 180 (17.30 fps)\n",
            "2020-05-22 09:31:22 [INFO]: Processing frame 200 (17.35 fps)\n",
            "2020-05-22 09:31:24 [INFO]: Processing frame 220 (17.39 fps)\n",
            "2020-05-22 09:31:26 [INFO]: Processing frame 240 (17.43 fps)\n",
            "2020-05-22 09:31:28 [INFO]: Processing frame 260 (17.48 fps)\n",
            "2020-05-22 09:31:30 [INFO]: Processing frame 280 (17.51 fps)\n",
            "2020-05-22 09:31:32 [INFO]: Processing frame 300 (17.54 fps)\n",
            "2020-05-22 09:31:34 [INFO]: Processing frame 320 (17.55 fps)\n",
            "2020-05-22 09:31:37 [INFO]: Processing frame 340 (17.54 fps)\n",
            "2020-05-22 09:31:39 [INFO]: Processing frame 360 (17.54 fps)\n",
            "2020-05-22 09:31:41 [INFO]: Processing frame 380 (17.52 fps)\n",
            "2020-05-22 09:31:43 [INFO]: Processing frame 400 (17.52 fps)\n",
            "2020-05-22 09:31:45 [INFO]: Processing frame 420 (17.53 fps)\n",
            "2020-05-22 09:31:47 [INFO]: Processing frame 440 (17.54 fps)\n",
            "2020-05-22 09:31:49 [INFO]: Processing frame 460 (17.56 fps)\n",
            "2020-05-22 09:31:51 [INFO]: Processing frame 480 (17.60 fps)\n",
            "2020-05-22 09:31:53 [INFO]: Processing frame 500 (17.66 fps)\n",
            "2020-05-22 09:31:55 [INFO]: Processing frame 520 (17.70 fps)\n",
            "2020-05-22 09:31:57 [INFO]: Processing frame 540 (17.74 fps)\n",
            "2020-05-22 09:31:59 [INFO]: Processing frame 560 (17.78 fps)\n",
            "2020-05-22 09:32:01 [INFO]: Processing frame 580 (17.82 fps)\n",
            "2020-05-22 09:32:03 [INFO]: Processing frame 600 (17.86 fps)\n",
            "2020-05-22 09:32:05 [INFO]: Processing frame 620 (17.88 fps)\n",
            "2020-05-22 09:32:07 [INFO]: Processing frame 640 (17.92 fps)\n",
            "2020-05-22 09:32:09 [INFO]: Processing frame 660 (17.94 fps)\n",
            "2020-05-22 09:32:11 [INFO]: Processing frame 680 (17.97 fps)\n",
            "2020-05-22 09:32:13 [INFO]: Processing frame 700 (17.99 fps)\n",
            "2020-05-22 09:32:15 [INFO]: Processing frame 720 (18.01 fps)\n",
            "2020-05-22 09:32:17 [INFO]: Processing frame 740 (18.02 fps)\n",
            "2020-05-22 09:32:18 [INFO]: save results to /content/gdrive/My Drive/5AUA0_Project_Group12_Team1/data/MOT17/images/train/../../../../Github_5AUA0_Project_G12T1/FairMOT/results/MOT17_val_hrnet_18_hrnet_scratchtrained/MOT17-13-SDP.txt\n",
            "2020-05-22 09:32:18 [INFO]: Evaluate seq: MOT17-13-SDP\n",
            "2020-05-22 09:32:18 [INFO]: Time elapsed: 299.06 seconds, FPS: 17.78\n",
            "              IDF1   IDP   IDR  Rcll  Prcn  GT  MT  PT ML   FP    FN IDs    FM  MOTA  MOTP IDt IDa IDm\n",
            "MOT17-02-SDP 63.0% 71.2% 56.5% 76.6% 96.5%  62  34  23  5  519  4339 141   608 73.1% 0.189  92  36  20\n",
            "MOT17-04-SDP 81.6% 83.5% 79.7% 86.2% 90.2%  83  51  23  9 4460  6585  23   150 76.7% 0.171   7  16   3\n",
            "MOT17-05-SDP 69.3% 75.1% 64.3% 83.9% 97.9% 133  79  48  6  126  1115  76   170 81.0% 0.205  96  21  55\n",
            "MOT17-09-SDP 68.1% 74.8% 62.5% 81.4% 97.5%  26  19   6  1  113   990  51   121 78.3% 0.173  38   8   7\n",
            "MOT17-10-SDP 68.9% 75.1% 63.6% 81.5% 96.1%  57  36  21  0  419  2381 157   414 77.0% 0.213 109  30  17\n",
            "MOT17-11-SDP 76.5% 78.9% 74.3% 91.1% 96.7%  75  56  16  3  289   839  39   123 87.6% 0.169  40  11  25\n",
            "MOT17-13-SDP 78.3% 82.2% 74.9% 88.1% 96.7% 110  82  21  7  350  1382  71   285 84.5% 0.204  63  24  39\n",
            "OVERALL      75.1% 79.4% 71.3% 84.3% 93.8% 546 357 158 31 6276 17631 558  1871 78.2% 0.184 445 146 166\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}